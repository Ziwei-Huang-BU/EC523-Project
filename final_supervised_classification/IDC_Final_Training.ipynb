{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Supervised Learning on Binary IDC Breast Cancer Classification Task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import random \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skimage.io import imread, imsave\n",
    "import skimage\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "import argparse\n",
    "from functools import partial\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU Info ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "Tesla V100-SXM2-16GB\n",
      "Tue Apr 26 03:39:27 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    45W / 300W |      3MiB / 16160MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#show gpu info\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "torch.cuda.current_device()\n",
    "device = 'cuda'\n",
    "\n",
    "gpu_info = !nvidia-smi -i 0\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define all Argument ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(arch='resnet18', batch_size=64, epochs=1000, model_load='', results_dir='./IDC-cache/cache-train-Cifar-randomini', resume=False, start_epoch=1, total_epoch=100)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Final Training Classifier on COVIDCT')\n",
    "\n",
    "parser.add_argument('-a', '--arch', default='resnet18')\n",
    "parser.add_argument('-bs','--batch-size', default=64, type=int, metavar='N', help='mini-batch size')\n",
    "parser.add_argument('--epochs', default=1000, type=int, metavar='N', help='number of total epochs to run')\n",
    "parser.add_argument('--results-dir', default='', type=str, metavar='PATH', help='path to cache (default: none)')\n",
    "parser.add_argument('--resume',default=False,help='if resume training ')\n",
    "parser.add_argument('--start-epoch',default = 1, type=int)\n",
    "parser.add_argument('--total-epoch',default = 100, type=int)\n",
    "parser.add_argument('--model-load',default = '',help='pretrained model file path')\n",
    "args = parser.parse_args('')\n",
    "\n",
    "args.results_dir = './IDC-cache/cache-' + 'train-Cifar-randomini'\n",
    "#args.model_load = './IDC-cache/cache-moco-Cifar/model_last.pth'\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metric ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define metric function \n",
    "\n",
    "def metric(predlist,tarlist,scorelist):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    TP = ((predlist == 1) & (tarlist == 1)).sum()\n",
    "    TN = ((predlist == 0) & (tarlist == 0)).sum()\n",
    "    FN = ((predlist == 0) & (tarlist == 1)).sum()\n",
    "    FP = ((predlist == 1) & (tarlist == 0)).sum()\n",
    "    print(TP,TN,FN,FP)\n",
    "    if TP+FP==0:\n",
    "        p=0.5\n",
    "    else:\n",
    "        p = TP / (TP + FP)\n",
    "    r = TP / (TP + FN)\n",
    "    F1 = 2 * r * p / (r + p)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "    AUC = roc_auc_score(tarlist,scorelist)\n",
    "    return TP,TN,FN,FP,p,r,F1,acc,AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Image Augmentation and DataLoader ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4437\n",
      "555\n",
      "558\n"
     ]
    }
   ],
   "source": [
    "DPATH = '/projectnb2/dl523/projects/COVIDCT2/dataset'\n",
    "label_map = {\"no IDC\": 0, \"IDC\": 1}\n",
    "torch.cuda.empty_cache()\n",
    "#define image augmentation for training set and val&test set\n",
    "\n",
    "train_transformer = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomResizedCrop(36),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.8072870370812287, 0.6357799672097822, 0.7357258879210914],\n",
    "                             std = [0.14257688600883628, 0.21227747141835426, 0.15241009580979106])\n",
    "])\n",
    "\n",
    "val_transformer = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(36),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.8072870370812287, 0.6357799672097822, 0.7357258879210914],\n",
    "                        std = [0.14257688600883628, 0.21227747141835426, 0.15241009580979106])\n",
    "])\n",
    "\n",
    "class BreastCancerDataset(Dataset):\n",
    "    def __init__(self, root_dir, npy_IDC, npy_NonIDC, transform=None, target_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Path to all data\n",
    "            npy_path (string): Path to the txt file with annotations.\n",
    "            transform: image augmentation \n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.npy_path = [npy_IDC, npy_NonIDC]\n",
    "        X_IDC = np.load(os.path.join(self.root_dir, self.npy_path[0]))\n",
    "        X_nonIDC = np.load(os.path.join(self.root_dir, self.npy_path[1]))\n",
    "        self.X = np.concatenate((X_IDC, X_nonIDC))\n",
    "        \n",
    "        Y_IDC = np.ones(X_IDC.shape[0],dtype=np.int64)\n",
    "        Y_nonIDC = np.zeros(X_nonIDC.shape[0],dtype=np.int64)\n",
    "        self.Y = np.concatenate((Y_IDC, Y_nonIDC))\n",
    "        \n",
    "        assert np.issubdtype(self.Y.dtype, np.integer)\n",
    "        assert self.Y.ndim == 1\n",
    "        assert np.issubdtype(self.X.dtype, np.uint8)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        ## get image & label\n",
    "        image, label = self.X[index], self.Y[index]\n",
    "        \n",
    "        ## transform \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "        sample = {'img': image,\n",
    "                  'label': label}\n",
    "        return sample    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    npy_IDC_train = 'IDC/train_IDC.npy'\n",
    "\n",
    "    npy_NonIDC_train = 'IDC/train_nonIDC.npy'\n",
    "\n",
    "\n",
    "    trainset = BreastCancerDataset(DPATH, npy_IDC_train, npy_NonIDC_train,\n",
    "                               transform=train_transformer)\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=64, drop_last=True,shuffle=True, num_workers=16)\n",
    "    npy_IDC_val = 'IDC/val_IDC.npy'\n",
    "\n",
    "    npy_NonIDC_val = 'IDC/val_nonIDC.npy'\n",
    "\n",
    "\n",
    "    valset = BreastCancerDataset(DPATH, npy_IDC_val, npy_NonIDC_val,\n",
    "                               transform=val_transformer)\n",
    "\n",
    "    val_loader = DataLoader(valset, batch_size=64, drop_last=False,shuffle=True, num_workers=16)\n",
    "    npy_IDC_test = 'IDC/test_IDC.npy'\n",
    "\n",
    "    npy_NonIDC_test = 'IDC/test_nonIDC.npy'\n",
    "\n",
    "\n",
    "    testset = BreastCancerDataset(DPATH, npy_IDC_test, npy_NonIDC_test,\n",
    "                               transform=val_transformer)\n",
    "\n",
    "    test_loader = DataLoader(testset, batch_size=64, drop_last=False,shuffle=True, num_workers=16)\n",
    "    \n",
    "    print(trainset.__len__())\n",
    "    print(valset.__len__())\n",
    "    print(testset.__len__())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': tensor([[[ 0.8566,  0.9116,  0.8566,  ...,  0.2514,  0.3065,  0.4715],\n",
       "          [ 0.9666,  0.9666,  0.9666,  ...,  0.1964,  0.2239,  0.3615],\n",
       "          [ 0.9666,  0.9666,  0.8566,  ..., -0.3537, -0.1611, -0.1061],\n",
       "          ...,\n",
       "          [ 0.8841,  0.9391,  0.9666,  ...,  0.3890,  0.2789,  0.3065],\n",
       "          [ 0.9391,  0.9391,  0.9116,  ...,  0.1689,  0.0314,  0.2239],\n",
       "          [ 0.9391,  0.9116,  0.6640,  ..., -0.0786, -0.1336, -0.0236]],\n",
       " \n",
       "         [[ 1.2170,  1.2355,  1.1800,  ..., -0.3533, -0.2794, -0.1870],\n",
       "          [ 1.4017,  1.4202,  1.4017,  ..., -0.4641, -0.4272, -0.2055],\n",
       "          [ 1.4202,  1.4017,  1.3094,  ..., -0.7412, -0.6304, -0.3533],\n",
       "          ...,\n",
       "          [ 1.3278,  1.3832,  1.3832,  ..., -0.7043, -0.7412, -0.6489],\n",
       "          [ 1.3648,  1.3648,  1.3648,  ..., -0.6119, -0.5011, -0.2240],\n",
       "          [ 1.3463,  1.3648,  1.0692,  ..., -0.6304, -0.3348, -0.2424]],\n",
       " \n",
       "         [[ 1.1422,  1.1679,  1.1164,  ..., -0.3759, -0.2730, -0.2215],\n",
       "          [ 1.3480,  1.3480,  1.3223,  ..., -0.5303, -0.4788, -0.2473],\n",
       "          [ 1.3480,  1.3223,  1.2451,  ..., -0.8133, -0.7104, -0.3759],\n",
       "          ...,\n",
       "          [ 1.2451,  1.2966,  1.2966,  ..., -0.8133, -0.8905, -0.7361],\n",
       "          [ 1.2708,  1.2708,  1.2708,  ..., -0.6847, -0.5560, -0.1958],\n",
       "          [ 1.2708,  1.2708,  0.9878,  ..., -0.6075, -0.3245, -0.1701]]]),\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validation and Test Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    total_num = 0 \n",
    "    \n",
    "    for batch_index, batch_samples in enumerate(train_loader):\n",
    "        \n",
    "        data, target = batch_samples['img'].to(device), batch_samples['label'].to(device) \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        criteria = nn.CrossEntropyLoss()\n",
    "        loss = criteria(output, target.long())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_num += target.size(0)\n",
    "        train_loss += loss.item()*target.size(0)                \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        train_correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "    \n",
    "        if batch_index % 3 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(\n",
    "                epoch, batch_index, len(train_loader),\n",
    "                100.0 * batch_index / len(train_loader), loss.item()))\n",
    "    return train_loss/total_num      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    total_num = 0 \n",
    "    correct = 0\n",
    "    results = []\n",
    "   \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        \n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "        for batch_index, batch_samples in enumerate(val_loader):\n",
    "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            total_num += target.size(0)\n",
    "            val_loss += criteria(output, target.long()).item()*target.size(0)\n",
    "            score = F.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "            targetcpu=target.long().cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "           \n",
    "    return val_loss/total_num, targetlist, scorelist, predlist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    total_num = 0 \n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "        for batch_index, batch_samples in enumerate(test_loader):\n",
    "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criteria(output, target.long())\n",
    "            \n",
    "            total_num += target.size(0)\n",
    "            test_loss += criteria(output, target.long()).item()/target.size(0)\n",
    "            \n",
    "            score = F.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "            targetcpu=target.long().cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "            \n",
    "    return test_loss/total_num, targetlist, scorelist, predlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18 Backbone ### \n",
    "\n",
    "**SplitBatchNorm**: simulate the multiple gpu parallel computing in only one GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified ResNet18 model \n",
    "class SplitBatchNorm(nn.BatchNorm2d):\n",
    "    def __init__(self, num_features, num_splits, **kw):\n",
    "        super().__init__(num_features, **kw)\n",
    "        self.num_splits = num_splits\n",
    "        \n",
    "    def forward(self, input):\n",
    "        N, C, H, W = input.shape\n",
    "        if self.training or not self.track_running_stats:\n",
    "            running_mean_split = self.running_mean.repeat(self.num_splits)\n",
    "            running_var_split = self.running_var.repeat(self.num_splits)\n",
    "            outcome = nn.functional.batch_norm(\n",
    "                input.view(-1, C * self.num_splits, H, W), running_mean_split, running_var_split, \n",
    "                self.weight.repeat(self.num_splits), self.bias.repeat(self.num_splits),\n",
    "                True, self.momentum, self.eps).view(N, C, H, W)\n",
    "            self.running_mean.data.copy_(running_mean_split.view(self.num_splits, C).mean(dim=0))\n",
    "            self.running_var.data.copy_(running_var_split.view(self.num_splits, C).mean(dim=0))\n",
    "            return outcome\n",
    "        else:\n",
    "            return nn.functional.batch_norm(\n",
    "                input, self.running_mean, self.running_var, \n",
    "                self.weight, self.bias, False, self.momentum, self.eps)\n",
    "\n",
    "\n",
    "class ModelBase(nn.Module):\n",
    "    \"\"\"\n",
    "    Common CIFAR ResNet recipe.\n",
    "    Comparing with ImageNet ResNet recipe, it:\n",
    "    (i) replaces conv1 with kernel=3, str=1\n",
    "    (ii) removes pool1\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dim=128, arch=None, bn_splits=16):\n",
    "        super(ModelBase, self).__init__()\n",
    "\n",
    "        # use split batchnorm\n",
    "        norm_layer = partial(SplitBatchNorm, num_splits=bn_splits) if bn_splits > 1 else nn.BatchNorm2d\n",
    "        resnet_arch = getattr(resnet, arch)\n",
    "        net = resnet_arch(num_classes=feature_dim, norm_layer=norm_layer)\n",
    "\n",
    "        self.net = []\n",
    "        for name, module in net.named_children():\n",
    "            if name == 'conv1':\n",
    "                module = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            if isinstance(module, nn.MaxPool2d):\n",
    "                continue\n",
    "            if isinstance(module, nn.Linear):\n",
    "                self.net.append(nn.Flatten(1))\n",
    "            self.net.append(module)\n",
    "\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        # note: not normalized here\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelBase(\n",
       "  (net): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): SplitBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): SplitBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SplitBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): SplitBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SplitBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): SplitBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SplitBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): SplitBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): SplitBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SplitBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): SplitBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SplitBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): SplitBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): SplitBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SplitBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): SplitBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SplitBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): SplitBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): SplitBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SplitBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (8): Flatten(start_dim=1, end_dim=-1)\n",
       "    (9): Linear(in_features=512, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelBase(arch='resnet18', bn_splits=8)\n",
    "model.to(device)\n",
    "\n",
    "#checkpoint = torch.load(args.model_load)\n",
    "\n",
    "#for i in model.state_dict():\n",
    "#    if 'encoder_q.'+i in checkpoint['state_dict']:\n",
    "#        model.state_dict()[i].copy_(checkpoint['state_dict']['encoder_q.'+i].data)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load The MoCo Pretrained Encoder  and Start Final Training for the Classifier ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "args.resume = False\n",
    "args.start_epoch = 1\n",
    "\n",
    "votenum = 10\n",
    "\n",
    "train_loss = np.zeros(1)\n",
    "val_loss = np.zeros(1)\n",
    "vote_pred = np.zeros(valset.__len__())\n",
    "vote_score = np.zeros(valset.__len__())\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "#for resuming \n",
    "if args.resume == True:\n",
    "    results = pd.read_csv(args.results_dir + '/train_val_log.csv',index_col=0)\n",
    "    checkpoint = torch.load(args.results_dir + '/model_last.pth')\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "else: \n",
    "    results = {'epoch':[],'train_loss':[],'val_loss':[],'val_accurary': [],'val_F1': [],'val_AUC': []}\n",
    "\n",
    "\n",
    "if not os.path.exists(args.results_dir):\n",
    "    os.mkdir(args.results_dir)\n",
    "\n",
    "for epoch in range(args.start_epoch, args.total_epoch+1):\n",
    "    trainloss = train(optimizer, epoch)\n",
    "    \n",
    "    valloss,targetlist, scorelist, predlist = val(epoch)\n",
    "    \n",
    "    train_loss += trainloss\n",
    "    val_loss += valloss \n",
    "    vote_pred += predlist \n",
    "    vote_score += scorelist \n",
    "    \n",
    "    if epoch % votenum == 0:\n",
    "        \n",
    "        # major vote\n",
    "        vote_pred[vote_pred <= (votenum/2)] = 0\n",
    "        vote_pred[vote_pred > (votenum/2)] = 1\n",
    "        vote_score = vote_score/votenum\n",
    "        TP,TN,FN,FP,p,r,F1,acc,AUC = metric(vote_pred,targetlist,vote_score)\n",
    "        results['epoch'].append(epoch)\n",
    "        results['train_loss'].append((train_loss/votenum).item())\n",
    "        results['val_loss'].append((val_loss/votenum).item())\n",
    "        results['val_accurary'].append(acc)\n",
    "        results['val_F1'].append(F1)\n",
    "        results['val_AUC'].append(AUC)\n",
    "        data_frame = pd.DataFrame(data=results)\n",
    "        data_frame.to_csv(args.results_dir + '/train_val_log.csv')\n",
    "        \n",
    "        #save the most current model \n",
    "        torch.save({'epoch': epoch, 'state_dict': model.state_dict(),\n",
    "                    'optimizer' : optimizer.state_dict(),}, args.results_dir + '/model_last.pth')\n",
    "        \n",
    "        vote_pred = np.zeros(valset.__len__())\n",
    "        vote_score = np.zeros(valset.__len__())\n",
    "        print('\\n The epoch is {}, 10 epoch avg: train loss: {:.4f}, val loss: {:.4f}, acc: {:.4f}, F1: {:.4f}, AUC: {:.4f}'.format(\n",
    "                epoch,(train_loss/votenum).item(),(val_loss/votenum).item(),acc,F1,AUC))\n",
    "        \n",
    "        train_loss = np.zeros(1)\n",
    "        val_loss = np.zeros(1)\n",
    "        vote_pred = np.zeros(valset.__len__())\n",
    "        vote_score = np.zeros(valset.__len__())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "model = ModelBase(arch='resnet18', bn_splits=8)\n",
    "model.to(device)\n",
    "\n",
    "checkpoint1 = torch.load('./IDC-cache/cache-train-Cifar-randomini/model_last.pth')\n",
    "checkpoint2 = torch.load('./IDC-cache/cache-train-Cifar-IDC/model_last.pth')\n",
    "#checkpoint3 = torch.load('Covid-cache/cache-train-Cifar-Covid/model_last.pth')\n",
    "#checkpoint4 = torch.load('./cache-train-Cifar-Luna-Covid/model_last.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Resnet18 Random Initialization (without Moco Pretraining) ### \n",
    "Final best performance:  acc, F1, AUC score: 0.810, 0.811, 0.901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227 225 55 51\n",
      "0.8100358422939068 0.8107142857142858 0.9007220680439922\n"
     ]
    }
   ],
   "source": [
    "#Resnet18 Random Initialization \n",
    "args.batch_size = 1\n",
    "\n",
    "model.load_state_dict(checkpoint1['state_dict'])\n",
    "epoch = 1\n",
    "\n",
    "vote_pred = np.zeros(testset.__len__())\n",
    "vote_score = np.zeros(testset.__len__())\n",
    "\n",
    "\n",
    "testloss,targetlist, scorelist, predlist = test(epoch)\n",
    "#print('target',targetlist)\n",
    "#print('score',scorelist)\n",
    "#print('predict',predlist)\n",
    "vote_pred = vote_pred + predlist \n",
    "vote_score = vote_score + scorelist \n",
    "\n",
    "TP,TN,FN,FP,p,r,F1,acc,AUC = metric(vote_pred,targetlist,vote_score)\n",
    "print(acc,F1,AUC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. two rounds of MoCo pretraining on Cifar-10 and IDC unlabeled Dataset  ### \n",
    "Final best performance:  acc, F1, AUC score: 0.821, 0.815, 0.907"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221 237 61 39\n",
      "0.8207885304659498 0.8154981549815498 0.9069405899886935\n"
     ]
    }
   ],
   "source": [
    "#moco: Resnet18 pretrained on Cifar and IDC dataset\n",
    "args.batch_size = 1\n",
    "\n",
    "model.load_state_dict(checkpoint2['state_dict'])\n",
    "epoch = 1\n",
    "\n",
    "vote_pred = np.zeros(testset.__len__())\n",
    "vote_score = np.zeros(testset.__len__())\n",
    "\n",
    "\n",
    "testloss,targetlist, scorelist, predlist = test(epoch)\n",
    "#print('target',targetlist)\n",
    "#print('score',scorelist)\n",
    "#print('predict',predlist)\n",
    "vote_pred = vote_pred + predlist \n",
    "vote_score = vote_score + scorelist \n",
    "\n",
    "TP,TN,FN,FP,p,r,F1,acc,AUC = metric(vote_pred,targetlist,vote_score)\n",
    "print(acc,F1,AUC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Code Refer to: ### \n",
    "[link] (https://github.com/UCSD-AI4H/COVID-CT/blob/master/baseline%20methods/Self-Trans/CT-predict-pretrain.ipynb)\n",
    "\n",
    "\n",
    "@article{zhao2020COVID-CT-Dataset,\n",
    "  title={COVID-CT-Dataset: a CT scan dataset about COVID-19},\n",
    "  author={Zhao, Jinyu and Zhang, Yichen and He, Xuehai and Xie, Pengtao},\n",
    "  journal={arXiv preprint arXiv:2003.13865}, \n",
    "  year={2020}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
